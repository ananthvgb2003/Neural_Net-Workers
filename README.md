![Screenshot 2024-01-05 005554 (1)](https://github.com/ananthvgb2003/Neural_Net-Workers/assets/120911455/407499c1-000f-4060-abda-5827a4b1f6e5)

# Sentiment Analysis using Audio

Transforming audio into dynamic pitches, our innovative tool analyzes speaker emotions, crafting personalized narratives that resonate. Your voice, your emotion, your cause â€“ perfectly pitched.

## About the Project

Here we present our solution to common communication struggles - a website built around the vision of deploying real-time Emotion Detection through voice or audio. Our model interprets the emotions of the speaker and generates a text with a perfectly pitched response, tailored to the cause specified by the user.

## Highlights

- Real-time emotion detection through voice/audio input
- Generates text responses tailored to the detected emotion and specified cause
- Trained on the Toronto Emotional Speech Set (TESS) dataset

## Login Information

For demonstration purposes, you can access the project using the following login credentials:

- **Username:** admin
- **Password:** admin

## Technologies Used

- HTML5
- CSS3
- JavaScript
- Scikit-learn
- Keras
- Python
- LSTM
- Streamlit

## Dataset

We trained our model using the [TESS (Toronto Emotional Speech Set) dataset](https://www.kaggle.com/datasets/ejlok1/toronto-emotional-speech-set-tess), ensuring a diverse and reliable foundation for emotion recognition.

## Performance
- Accuracy: 93% on the TESS dataset
- Detects 7 emotions: joy, sadness, anger, fear, disgust, surprise, neutral

---

